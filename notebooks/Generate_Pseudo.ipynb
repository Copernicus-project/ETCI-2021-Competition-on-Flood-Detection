{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses [this blog post](https://medium.com/cloud-to-street/jumpstart-your-machine-learning-satellite-competition-submission-2443b40d0a5a) and [this video](https://www.youtube.com/watch?v=SsnWM1xWDu4) as references."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\program files (x86)\\python\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\program files (x86)\\python\\lib\\site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\program files (x86)\\python\\lib\\site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\program files (x86)\\python\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: pickleshare in c:\\program files (x86)\\python\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\program files (x86)\\python\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\program files (x86)\\python\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: backcall in c:\\program files (x86)\\python\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\program files (x86)\\python\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
      "Requirement already satisfied: colorama in c:\\program files (x86)\\python\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: pygments in c:\\program files (x86)\\python\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\program files (x86)\\python\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\program files (x86)\\python\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\program files (x86)\\python\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\program files (x86)\\python\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\program files (x86)\\python\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\program files (x86)\\python\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\program files (x86)\\python\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\program files (x86)\\python\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\program files (x86)\\python\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\program files (x86)\\python\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in c:\\program files (x86)\\python\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\program files (x86)\\python\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets) (302)\n",
      "Requirement already satisfied: prometheus-client in c:\\program files (x86)\\python\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\program files (x86)\\python\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: nbconvert in c:\\program files (x86)\\python\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\program files (x86)\\python\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: jinja2 in c:\\program files (x86)\\python\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\program files (x86)\\python\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: wcwidth in c:\\program files (x86)\\python\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files (x86)\\python\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\program files (x86)\\python\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.4)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\program files (x86)\\python\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files (x86)\\python\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\program files (x86)\\python\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\program files (x86)\\python\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in c:\\program files (x86)\\python\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: testpath in c:\\program files (x86)\\python\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: bleach in c:\\program files (x86)\\python\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\program files (x86)\\python\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\program files (x86)\\python\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.4)\n",
      "Requirement already satisfied: pycparser in c:\\program files (x86)\\python\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: webencodings in c:\\program files (x86)\\python\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\program files (x86)\\python\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\program files (x86)\\python\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mz4KCyB4Pw6Q"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import ttach as tta\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1QXI66oQ0z_"
   },
   "source": [
    "## Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOi7wYOKQyjF",
    "outputId": "916e5607-3933-41d5-fefb-70b0a1e7814b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:/Users/Shuo/tiles_ST1_20200730_MMR_img\n",
      "Number of test temporal-regions: 0\n"
     ]
    }
   ],
   "source": [
    "# path to dataset root directory\n",
    "dset_root = 'Y:/Users/Shuo/'\n",
    "\n",
    "test_dir = os.path.join(dset_root, 'tiles_ST1_20200730_MMR_img')\n",
    "print(test_dir)\n",
    "n_test_regions = len(glob(test_dir+'/*/'))\n",
    "print('Number of test temporal-regions: {}'.format(n_test_regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWNe2TxWVrQ1"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lHnXysQzVtr_"
   },
   "outputs": [],
   "source": [
    "def get_test_id(path):\n",
    "    return path.split(\"_\")[0] + \"_\" + path.split(\"_\")[1]\n",
    "\n",
    "def make_im_name(id, suffix):\n",
    "    return id.split(\".\")[0] + f\"_{suffix}.png\"\n",
    "\n",
    "def s1_to_rgb(vv_image, vh_image):\n",
    "    ratio_image = np.clip(np.nan_to_num(vh_image/vv_image, 0), 0, 1)\n",
    "    rgb_image = np.stack((vv_image, vh_image, 1-ratio_image), axis=2)\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMhA2NnmQ5-G"
   },
   "source": [
    "## Create dataframe\n",
    "\n",
    "As per [the competition website](https://nasa-impact.github.io/etci2021/), the submission file needs to be generated following a particular sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -q https://git.io/JsRTE -O test_sentinel.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "B2oExzdPiPfR",
    "outputId": "d955d599-b1be-485c-88c0-214444e10086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Y:/Users/Shuo/tiles_ST1_20200730_MMR_img/ST1_20200808_MMR_1C48_12_54.png\n",
      "Y:/Users/Shuo/tiles_ST1_20200730_MMR_img/ST1_20200808_MMR_1C48_12_54.png\n",
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "# test_file_sequence = pd.read_csv(\"test_sentinel.csv\", header=None)\n",
    "# test_file_sequence = test_file_sequence.values.squeeze().tolist()\n",
    "test_file_sequence = os.listdir(test_dir)[0:100]\n",
    "print(len(test_file_sequence))\n",
    "test_file_sequence = list(filter(lambda f: '.png' in f, test_file_sequence))\n",
    "# print(test_file_sequence)\n",
    "# all_test_vv = [os.path.join(test_dir, get_test_id(id), \"tiles\", \"vv\", make_im_name(id, \"vv\")) \n",
    "#                                                                 for id in test_file_sequence]\n",
    "all_test_vv = ['/'.join([test_dir, id]) for id in test_file_sequence]\n",
    "print(all_test_vv[0])\n",
    "all_test_vh = ['/'.join([test_dir, id]) for id in test_file_sequence]\n",
    "# all_test_vh = [os.path.join(test_dir, get_test_id(id), \"tiles\", \"vh\", make_im_name(id, \"vh\")) \n",
    "#                                                                 for id in test_file_sequence]\n",
    "print(all_test_vh[0])\n",
    "paths = {'vv_image_path': all_test_vv,\n",
    "         'vh_image_path': all_test_vh,\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(paths)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW5yZ_I0RFK6"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Gus4cgUzdx3o"
   },
   "outputs": [],
   "source": [
    "class ETCIDataset(Dataset):\n",
    "    def __init__(self, dataframe, split, transform=None):\n",
    "        self.split = split\n",
    "        self.dataset = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = {}\n",
    "        \n",
    "        df_row = self.dataset.iloc[index]\n",
    "\n",
    "        # load vv and vh images\n",
    "        vv_image = cv2.imread(df_row['vv_image_path'], 0) / 255.0\n",
    "        vh_image = cv2.imread(df_row['vh_image_path'], 0) / 255.0\n",
    "        \n",
    "        # convert vv and ch images to rgb\n",
    "        rgb_image = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "        if self.split == 'test':\n",
    "            # no flood mask should be available\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')\n",
    "            example['vv_image_path'] = df_row['vv_image_path']\n",
    "            example['vh_image_path'] = df_row['vh_image_path']\n",
    "        else:\n",
    "            # load ground truth flood mask\n",
    "            flood_mask = cv2.imread(df_row['flood_label_path'], 0) / 255.0\n",
    "\n",
    "            # compute transformations\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=rgb_image, mask=flood_mask)\n",
    "                rgb_image = augmented['image']\n",
    "                flood_mask = augmented['mask']\n",
    "\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')\n",
    "            example['mask'] = flood_mask.astype('int64')\n",
    "\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "ls9VrVu1d3Ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array([[[1.        , 1.        , 1.        , ..., 1.        ,\n",
      "         0.69803923, 0.53333336],\n",
      "        [0.6784314 , 1.        , 1.        , ..., 1.        ,\n",
      "         0.7764706 , 0.4862745 ],\n",
      "        [0.6117647 , 0.8784314 , 1.        , ..., 0.8862745 ,\n",
      "         0.68235296, 0.46666667],\n",
      "        ...,\n",
      "        [0.6313726 , 0.44313726, 0.56078434, ..., 0.5647059 ,\n",
      "         0.9411765 , 1.        ],\n",
      "        [0.42745098, 0.47843137, 0.6509804 , ..., 0.8156863 ,\n",
      "         1.        , 0.9019608 ],\n",
      "        [0.4509804 , 0.5529412 , 0.6117647 , ..., 1.        ,\n",
      "         1.        , 0.88235295]],\n",
      "\n",
      "       [[1.        , 1.        , 1.        , ..., 1.        ,\n",
      "         0.69803923, 0.53333336],\n",
      "        [0.6784314 , 1.        , 1.        , ..., 1.        ,\n",
      "         0.7764706 , 0.4862745 ],\n",
      "        [0.6117647 , 0.8784314 , 1.        , ..., 0.8862745 ,\n",
      "         0.68235296, 0.46666667],\n",
      "        ...,\n",
      "        [0.6313726 , 0.44313726, 0.56078434, ..., 0.5647059 ,\n",
      "         0.9411765 , 1.        ],\n",
      "        [0.42745098, 0.47843137, 0.6509804 , ..., 0.8156863 ,\n",
      "         1.        , 0.9019608 ],\n",
      "        [0.4509804 , 0.5529412 , 0.6117647 , ..., 1.        ,\n",
      "         1.        , 0.88235295]],\n",
      "\n",
      "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32), 'vv_image_path': 'Y:/Users/Shuo/tiles_ST1_20200730_MMR_img/ST1_20200808_MMR_1C48_12_54.png', 'vh_image_path': 'Y:/Users/Shuo/tiles_ST1_20200730_MMR_img/ST1_20200808_MMR_1C48_12_54.png'}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ETCIDataset(test_df, split='test', transform=None)\n",
    "print(test_dataset[0])\n",
    "batch_size = 2 * torch.cuda.device_count()\n",
    "print(batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n",
    "                         num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Uc2z3thWRG5Q"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling and pseudo labeling\n",
    "\n",
    "We start by defining the model classes and the paths to their pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_mobilenet = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\", \n",
    "    encoder_weights=None, \n",
    "    in_channels=3,                  \n",
    "    classes=2                      \n",
    ")\n",
    "\n",
    "upp_mobilenet = smp.UnetPlusPlus(\n",
    "    encoder_name=\"mobilenet_v2\", \n",
    "    encoder_weights=None, \n",
    "    in_channels=3,                  \n",
    "    classes=2                      \n",
    ")\n",
    "\n",
    "model_defs = [unet_mobilenet, upp_mobilenet]\n",
    "model_paths = [\"../weights/unet_mobilenet_v2_0.pth\",\n",
    "              \"../weights/upp_mobilenetv2_0.pth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: After a round of pseudo-labeling, one should also incorporate the latest fine-tuned model (obtained by running the `src/train_pseudo_label.py` script) in the ensemble for better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_single(model_def, weights, dir_path, conf_thres=0.95, pixel_thres=0.9):\n",
    "    models = []\n",
    "    for model_def, weight in zip(model_defs, weights):\n",
    "        model_def.load_state_dict(torch.load(weight))\n",
    "        model = tta.SegmentationTTAWrapper(model_def, tta.aliases.d4_transform(), merge_mode=\"mean\") \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        models.append(model)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    vv_s = []\n",
    "    vh_s = []\n",
    "    masks = []\n",
    "    print(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            # load image and mask into device memory\n",
    "            image = batch['image'].to(device)\n",
    "\n",
    "            # pass images into model\n",
    "            preds = []\n",
    "            for model in models:\n",
    "                pred = model(image)\n",
    "                preds.append(pred.detach().cpu().numpy())\n",
    "            \n",
    "            preds = np.array(preds)\n",
    "            preds = np.mean(preds, axis=0) # Mean over ensembles\n",
    "            \n",
    "            filter_preds, _ = nn.Softmax(dim=1)(torch.tensor(preds)).max(1) # Apply softmax -> take max\n",
    "            # Shape: (batch_size, 256, 256)\n",
    "            filter_preds = filter_preds.numpy()\n",
    "            \n",
    "            # Are `pixel_thres`% of the pixels in an entry greater `conf_thres`? \n",
    "            filerted = np.sum(filter_preds > conf_thres, axis = (1, 2)) > pixel_thres * 256 * 256 # 256: image size\n",
    "\n",
    "            for idx, filter_ in enumerate(filerted): # entries: (batch_size, 256, 256)\n",
    "                if filter_:\n",
    "                    vv_s.append(batch['vv_image_path'][idx])\n",
    "                    vh_s.append(batch['vh_image_path'][idx])\n",
    "                    entry = nn.Softmax(dim=0)(torch.tensor(preds[idx])).argmax(0).numpy() * 255. \n",
    "                    \n",
    "                    pseudo_path = \"_\".join(batch['vv_image_path'][idx].split(\"/\")[-1].split(\"_\")[:])\n",
    "                    pseudo_path = os.path.join(dir_path, pseudo_path)\n",
    "                    masks.append(pseudo_path)\n",
    "                    cv2.imwrite(pseudo_path, entry.astype(\"float32\"))\n",
    "                    \n",
    "    return vv_s, vh_s, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001B1274F4EB0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9f32b8d25b4e13a059b4ce4cb119c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "vv_s, vh_s, masks =  get_predictions_single(model_defs, model_paths, \"pseudo_labels\")\n",
    "assert len(vv_s) == len(vh_s) == len(masks)\n",
    "\n",
    "paths = {'vv_image_path': vv_s,\n",
    "         'vh_image_path': vh_s,\n",
    "         'flood_label_path': masks\n",
    "}\n",
    "\n",
    "pseudo_df = pd.DataFrame(paths)\n",
    "print(pseudo_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_df.to_csv(\"pseudo_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe is then used to retrain any of the model used in the ensemble here (refer to `src/train_pseudo_label.py`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ECTI_Jumpstart.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}